# -*- coding: utf-8 -*-
"""3pct_prediction_Tavion_Sims.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A7MFbn1z1cEysEj_CuKgfzgiFmvt72AB

# **Task:**
Predict each playerâ€™s three-point percentage at the end of the 2022-23 season given their shooting
statistics from October/November 2022. You have the last 12 columns to create your prediction and the
second column, three_pct_season to test your prediction accuracy (data dictionary below).

# **Reference Information & Description**
"""

#import packages
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""# **Data Digestion**"""

#Reading fas_2024 dataset

fp = r"/content/drive/MyDrive/fas_2024.csv"

df = pd.read_csv(fp)

df.head()

df.tail()

#Now we will go through the proccess of getting info about the dataset
df.info()

#Taking note:
#14 total columns
#108 rows
#1 string type
#7 float types
#6 Integer types

#There didnt seem to be Null values in the data but to be safe we'll check here

df.isnull().sum()

#No null values present in data
#Good clean dataset

#Now lets look at our stats on the dataset

df.describe()

"""# **Visualizing the Dataset**"""

#Here we want to check the distribution of our numerical columns
#This gives us more insights about how the data is skewed per column

columns = list(df)[:13]

df[columns].hist(figsize=(12,50),layout=(14,4))

plt.show()

"""# **More Visuals Exploring the Dataset**"""

#We want to look into the correlation of the Dataset and how closely some attributes relate to one another

df.corr()

#Now that I have my correlation I will put it into a heat map to better visualize it

plt.subplots(figsize=(15,10))

sns.heatmap(df.corr().abs(), vmax=1,square=True,annot=True,cmap='viridis')

plt.title("Correlation Between FAS_2024 Dataset")


plt.show()

"""# **Analysis Based off Correlation:**
Based off of the heatmap, this helped me indentify some features that I would like to use in in concurrent of our prediction for three_pct_season.
I will first go through and run the whole dataset, and adjust my feature selections after accuracy and models predictions.

# **Data Preproccessing**
"""

#Check Data Types

df.dtypes

#We know there is no null values but it is always good to look again before moving forward in the Preproccessing section.

df.isna().sum()

"""#**Splitting X and y**"""

#Splitting X
#X will be our features

X = df[['upr_paint_pct_oct_nov','three_cnr_pct_oct_nov' ,'three_non_cnr_pct_oct_nov','ft_pct_oct_nov']]
X

#Splitting y
#y is our prediction varible we want

y = df['three_pct_season']

y

"""# **Train/Test/Split Data**"""

#import train_test_split from scikit learn
from sklearn.model_selection import train_test_split
#Now we need to split and train our data
#Train test split is used to evaluate the performance of a Machine Leaning model
X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.20,random_state=42)

"""# **Modeling**"""

#import Linear Regression model from scikit learn
from sklearn.linear_model import LinearRegression

#Modeling
lr = LinearRegression()
lr.fit(X_train,y_train)

#Predictions
y_pred = lr.predict(X_test)

# Adding 'Name' column to the testing dataset for post-processing
X_test_with_names = df.loc[X_test.index, ['Name']].copy()

#Creating a DataFrame with player names and predicted three-point percentages
predictions_df = pd.DataFrame({'Name': X_test_with_names['Name'], 'Predicted_Three_Point_Percentage': y_pred})

#Adding the three_pct_season as the actual_three_pct for the season
predictions_df['Actual_Three_Pct'] = df.loc[X_test.index, 'three_pct_season'].values

# Displaying the DataFrame
predictions_df

#Creating and plotting a scatter plot with a best fit lineto visualize Actual vs Predicted 3 point percentages
sns.set(style="whitegrid")

#scatter plot comparing actual vs. predicted three-point percentages
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Actual_Three_Pct', y='Predicted_Three_Point_Percentage', data=predictions_df, color='blue', alpha=0.7)

#Adding Line of best fit
plt.plot([min(predictions_df['Actual_Three_Pct']), max(predictions_df['Actual_Three_Pct'])],
         [min(predictions_df['Actual_Three_Pct']), max(predictions_df['Actual_Three_Pct'])],
         color='red', linestyle='--', linewidth=2)

plt.xlabel('Actual Three-Point Percentage')
plt.ylabel('Predicted Three-Point Percentage')
plt.title('Actual vs. Predicted Three-Point Percentages')

plt.show()

#plot actual vs predicted
#Here we are comparing the test data set(Which is the correct data and labels) and the prediction dataset

c = [i for i in range (1,len(y_test)+1,1)]

plt.plot(c,y_test,color='r',linestyle='-')
plt.plot(c,y_pred,color='b',linestyle='-')
plt.xlabel('Scores')
plt.ylabel('index')
plt.title('Prediction')
plt.ticklabel_format(axis="y", style="plain")
plt.show()

#Our prediction data is in blue
#Our historical or training set is in red

#plotting the error
#Here we are plotting the errorr values that were in the predicted set
c = [i for i in range(1,len(y_test)+1,1)]
plt.plot(c,y_test-y_pred,color='green',linestyle='-')
plt.xlabel('index')
plt.ylabel('Error')
plt.title('Error Value')
plt.ticklabel_format(axis="y", style="plain")
plt.show()

#Intercept and coeff of the line
print('Intercept of the model:',lr.intercept_)
print('Coefficient of the line:', lr.coef_)

#Accuracy metrics from scikit learn
from sklearn import metrics
#MAE definition:is a measure of the average size of the mistakes in a collection of predictions, without taking their direction into account
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))
#MSE: measures how close a regression line is to a set of data points.
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))
#is one of the most commonly used measures for evaluating the quality of predictions. It shows how far predictions fall from measured true values
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))
print('r square :' , metrics.r2_score(y_test, y_pred))

#r-squared shows how well the data fit the regression model
#a good r-squared values is between 0.50 to 0.99
#This output is 0.39, that is okay and there is always room for improvement but this is good if you take into account our MAE,MSE, and RMSE!

